{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c78cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c44d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23-year-old white female presents complaint al...</td>\n",
       "      <td>subjective:, 23-year-old white female presents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>consult laparoscopic gastric bypass.</td>\n",
       "      <td>past medical history:, difficulty climbing sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>consult laparoscopic gastric bypass.</td>\n",
       "      <td>history present illness: , seen abc today. ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2-d m-mode. doppler.</td>\n",
       "      <td>2-d m-mode: , ,1. left atrial enlargement left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2-d echocardiogram</td>\n",
       "      <td>1. left ventricular cavity size wall thickness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  23-year-old white female presents complaint al...   \n",
       "1           1               consult laparoscopic gastric bypass.   \n",
       "2           2               consult laparoscopic gastric bypass.   \n",
       "3           3                               2-d m-mode. doppler.   \n",
       "4           4                                 2-d echocardiogram   \n",
       "\n",
       "                                       transcription  \n",
       "0  subjective:, 23-year-old white female presents...  \n",
       "1  past medical history:, difficulty climbing sta...  \n",
       "2  history present illness: , seen abc today. ple...  \n",
       "3  2-d m-mode: , ,1. left atrial enlargement left...  \n",
       "4  1. left ventricular cavity size wall thickness...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./mt_samples_preproc.csv',encoding='iso-8859-1')\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db27d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655fd77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(hello) hi there .man tiger caller who is that is not it ? wall-e\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text = text.split() # convert have'nt -> have not\n",
    "    for i in range(len(text)):\n",
    "        word = text[i]\n",
    "        if word in contraction_mapping:\n",
    "            text[i] = contraction_mapping[word]\n",
    "    return ' '.join(text)\n",
    "#define a function for POS tag\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# define text cleaning process\n",
    "def clean_text(text):\n",
    "    ## Remove puncuation\n",
    "    text=re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]',' ',text).lower().split()\n",
    "    ## Remove stop words\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    text = [w for w in text if w not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    wnl=WordNetLemmatizer()\n",
    "    text=[wnl.lemmatize(i,get_wordnet_pos(i)) for i in text]\n",
    "    return preprocess(' '.join(text))\n",
    "\n",
    "sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n",
    "print(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1f3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['transcription'] = df['transcription'].apply(lambda x:preprocess(x))\n",
    "#df['description'] = df['description'].apply(lambda x:preprocess(x))\n",
    "#print(df['description'][1],df['transcription'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63d7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['transcription']),np.array(df['description']),test_size=0.1,random_state=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0aaa285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history present illness: , seen abc today. pleasant gentleman 42 years old, 344 pounds. 59\". bmi 51. overweight ten years since age 33, highest 358 pounds, lowest 260. pursuing surgical attempts weight loss feel good, get healthy, begin exercise again. wants able exercise play volleyball. physically, sluggish. gets tired quickly. go often. loses weight always regains gains back lost. biggest weight loss 25 pounds three months gained back. six months drinking alcohol taking many calories. multiple commercial weight loss programs including slim fast one month one year ago atkins diet one month two years ago.,past medical history: , difficulty climbing stairs, difficulty airline seats, tying shoes, used public seating, difficulty walking, high cholesterol, high blood pressure. asthma difficulty walking two blocks going eight ten steps. sleep apnea snoring. diabetic, medication. joint pain, knee pain, back pain, foot ankle pain, leg foot swelling. hemorrhoids.,past surgical history: , includes orthopedic knee surgery.,social history: , currently single. drinks alcohol ten twelve drinks week, drink five days week binge drink. smokes one half pack day 15 years, recently stopped smoking past two weeks.,family history: , obesity, heart disease, diabetes. family history negative hypertension stroke.,current medications:, include diovan, crestor, tricor.,miscellaneous/eating history: ,he says couple friends heart attacks died. used drink everyday, stopped two years ago. drinks weekends. second week chantix, medication come smoking completely. eating, eats bad food. single. eats things like bacon, eggs, cheese, cheeseburgers, fast food, eats four times day, seven morning, noon, 9 p.m., 2 a.m. currently weighs 344 pounds 59\". ideal body weight 160 pounds. 184 pounds overweight. lost 70 excess body weight would 129 pounds would get 215.,review systems: , negative head, neck, heart, lungs, gi, gu, orthopedic, skin. also positive gout. denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, pulmonary embolism, cva. denies venous insufficiency thrombophlebitis. denies shortness breath, copd, emphysema. denies thyroid problems, hip pain, osteoarthritis, rheumatoid arthritis, gerd, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, rectal bleeding, polyps, incontinence stool, urinary stress incontinence, cancer. denies cellulitis, pseudotumor cerebri, meningitis, encephalitis.,physical examination: ,he alert oriented x 3. cranial nerves ii-xii intact. neck soft supple. lungs: positive wheezing bilaterally. heart regular rhythm rate. abdomen soft. extremities: 1+ pitting edema.,impression/plan:, explained risks potential complications laparoscopic gastric bypass detail include bleeding, infection, deep venous thrombosis, pulmonary embolism, leakage gastrojejuno-anastomosis, jejunojejuno-anastomosis, possible bowel obstruction among potential complications. understands. wants proceed workup evaluation laparoscopic roux-en-y gastric bypass. need get letter approval dr. xyz. need see nutritionist mental health worker. need upper endoscopy either dr. xyz. need go dr. xyz previously sleep study. need another sleep study. need h. pylori testing, thyroid function tests, lfts, glycosylated hemoglobin, fasting blood sugar. performed, submit insurance approval.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c082103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preoperative diagnosis:, prostate cancer.,postoperative diagnosis: , prostate cancer.,operative procedure: , radical retropubic prostatectomy pelvic lymph node dissection.,anesthesia: ,general epidural,estimated blood loss: , 800 cc.,complications: , none.,indications surgery: , 64-year-old man adenocarcinoma prostate confirmed needle biopsies. elected undergo radical retropubic prostatectomy pelvic lymph node dissection. potential complications include, limited to:,1. infection.,2. bleeding.,3. incontinence.,4. impotence.,5. deep venous thrombosis.,6. recurrence cancer.,procedure detail: , epidural anesthesia administered anesthesiologist holding area. preoperative antibiotic also given preoperative holding area. patient taken operating room general lma anesthesia administered. patient shaved prepped using betadine solution. sterile 16-french foley catheter inserted bladder clear urine drain. midline infraumbilical incision performed. rectus fascia opened sharply. perivesical space retropubic space developed bluntly. bookwalter retractor placed. bilateral obturator pelvic lymphadenectomy performed. obturator nerve identified untouched. margin resection lymph node bilaterally coopers ligament, medial edge external iliac artery, bifurcation common iliac vein, obturator nerve, bladder. hemostasis lymphostasis achieved using silk ties hemo clips. lymph nodes palpably normal set permanent section. bookwalter retractor repositioned endopelvic fascia opened bilaterally using metzenbaum scissors. puboprostatic ligament taken sharply. superficial dorsal vein complex prostate bunched using allis clamp tied using 2-0 silk sutures. deep dorsal vein complex bunched using allis membranous urethral area. dorsal vein complex ligated using 0 vicryl suture ct-1 needle. allis clamp removed dorsal vein complex transected using metzenbaum scissors. urethra identified dissected out. urethral opening made distal apex prostate using metzenbaum scissors. extended circumferentially foley catheter could seen clearly. 2-0 monocryl sutures placed urethral stump evenly spaced anastomosis performed later. foley catheter removed posteriormost aspect urethra rectourethralis muscle transected. lateral pelvic fascia opened bilaterally sweep neurovascular bundles laterally sides. plane denonvilliers fascia perirectal fat developed sharply. tension placed neurovascular bundle point time. prostate dissected rectal wall easily. seminal vesicles identified, fascia covering opened transversely. seminal vesicles dissected small bleeding vessels leading clipped using medium clips transected. bladder neck dissected carefully spare bladder neck muscles. prostate dissected bladder neck circumferentially mucosa lining bladder neck transected releasing entire specimen. specimen inspected appeared completely intact. sent permanent section. bladder neck mucosa everted using 4-0 chromic sutures. inspection prostatic bed revealed bleeding vessels. sutures, placed previously onto urethral stump, placed onto bladder neck. posterior sutures placed, foley placed urethra bladder neck. 20-french foley catheter used. anterior sutures placed. foley inflated. bed straightened sutures tied sequentially anteriorly posteriorly. mild traction foley catheter placed assure anastomosis tight. two 19-french blake drains placed perivesical spaces. anchored skin using 2-0 silk sutures. instrument counts, lab counts, sponge counts verified correct, patient closed. fascia closed running fashion using 1 pds. subcutaneous tissue closed using 2-0 vicryl suture. skin approximated using metallic clips. patient tolerated operation well.\n",
      "radical retropubic prostatectomy pelvic lymph node dissection due prostate cancer.\n"
     ]
    }
   ],
   "source": [
    "x = pd.Series(x_tr)\n",
    "y = pd.Series(y_tr)\n",
    "print(x[50],y[50],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073e3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = pd.Series(x_val)\n",
    "y_v = pd.Series(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0a27ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9aa0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "620124c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(summary)\n",
    "        output_lang = Lang(text)\n",
    "    else:\n",
    "        input_lang = Lang(text)\n",
    "        output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e695e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    #print(\"Counted words:\")\n",
    "    #print(input_lang.name, input_lang.n_words)\n",
    "    #print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a66d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 4464 sentence pairs\n",
      "Counting words...\n",
      "['history present illness:, 67-year-old gentleman presented emergency room chest pain, cough, hemoptysis, shortness breath, recent 30-pound weight loss. ct scan done chest demonstrated bilateral hilar adenopathy extension subcarinal space well large 6-cm right hilar mass, consistent primary lung carcinoma. also question liver metastases time.,operation performed:, fiberoptic bronchoscopy endobronchial biopsies.,the bronchoscope passed airway noted large, friable tumor blocking bronchus intermedius right. tumor extended carina, involving lingula left upper lobe, appearing malignant. approximately 15 biopsies taken tumor.,attention directed left upper lobe lingula. epinephrine already instilled multiple biopsies taken lingula left upper lobe placed separate container histologic review. approximately eight biopsies taken left upper lobe.', 'fiberoptic bronchoscopy endobronchial biopsies. ct scan done chest demonstrated bilateral hilar adenopathy extension subcarinal space well large 6-cm right hilar mass, consistent primary lung carcinoma.']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData( x, y , False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c73af05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496 sentence pairs\n",
      "Counting words...\n"
     ]
    }
   ],
   "source": [
    "input_lang_v, output_lang_v, pairs_v = prepareData( x_v, y_v , False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb53548",
   "metadata": {},
   "source": [
    "#### Encoder - GRU model with 300 units. Embedding size - input vocabulary length.\n",
    "#### Decoder - GRU with Attention layer, 300 units. Embedding size - output (summary) vocabulary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c2d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ba45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff23c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f82603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e64d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    arr = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            arr.append(lang.word2index[word])\n",
    "        except:\n",
    "            arr.append(0)\n",
    "    return arr\n",
    "            \n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b38f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9b0541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb04424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fdc11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    print(\"Training....\")\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iterator in range(1, n_iters + 1):\n",
    "        if iterator% 1000 == 0:\n",
    "            print(iterator,\"/\",n_iters + 1)\n",
    "        training_pair = training_pairs[iterator - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iterator % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iterator / n_iters),\n",
    "                                         iterator, iterator / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iterator % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36334ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2398b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36edc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_y(encoder, decoder, n=10):\n",
    "    for pair in pairs_v:\n",
    "        \n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "940f529b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "1000 / 55001\n",
      "2000 / 55001\n",
      "3000 / 55001\n",
      "4000 / 55001\n",
      "5000 / 55001\n",
      "48m 33s (- 485m 31s) (5000 9%) 5.3104\n",
      "6000 / 55001\n",
      "7000 / 55001\n",
      "8000 / 55001\n",
      "9000 / 55001\n",
      "10000 / 55001\n",
      "98m 11s (- 441m 52s) (10000 18%) 4.9407\n",
      "11000 / 55001\n",
      "12000 / 55001\n",
      "13000 / 55001\n",
      "14000 / 55001\n",
      "15000 / 55001\n",
      "145m 40s (- 388m 28s) (15000 27%) 4.2547\n",
      "16000 / 55001\n",
      "17000 / 55001\n",
      "18000 / 55001\n",
      "19000 / 55001\n",
      "20000 / 55001\n",
      "197m 7s (- 344m 57s) (20000 36%) 3.6081\n",
      "21000 / 55001\n",
      "22000 / 55001\n",
      "23000 / 55001\n",
      "24000 / 55001\n",
      "25000 / 55001\n",
      "246m 32s (- 295m 51s) (25000 45%) 2.9709\n",
      "26000 / 55001\n",
      "27000 / 55001\n",
      "28000 / 55001\n",
      "29000 / 55001\n",
      "30000 / 55001\n",
      "296m 42s (- 247m 15s) (30000 54%) 2.4623\n",
      "31000 / 55001\n",
      "32000 / 55001\n",
      "33000 / 55001\n",
      "34000 / 55001\n",
      "35000 / 55001\n",
      "346m 48s (- 198m 10s) (35000 63%) 2.0956\n",
      "36000 / 55001\n",
      "37000 / 55001\n",
      "38000 / 55001\n",
      "39000 / 55001\n",
      "40000 / 55001\n",
      "394m 54s (- 148m 5s) (40000 72%) 1.8793\n",
      "41000 / 55001\n",
      "42000 / 55001\n",
      "43000 / 55001\n",
      "44000 / 55001\n",
      "45000 / 55001\n",
      "442m 31s (- 98m 20s) (45000 81%) 1.6980\n",
      "46000 / 55001\n",
      "47000 / 55001\n",
      "48000 / 55001\n",
      "49000 / 55001\n",
      "50000 / 55001\n",
      "492m 5s (- 49m 12s) (50000 90%) 1.6000\n",
      "51000 / 55001\n",
      "52000 / 55001\n",
      "53000 / 55001\n",
      "54000 / 55001\n",
      "55000 / 55001\n",
      "543m 39s (- 0m 0s) (55000 100%) 1.4434\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "hidden_size = 300\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 55000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "062cea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1.state_dict(), './enc3.w')\n",
    "torch.save(attn_decoder1.state_dict(), './att3.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cff7b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluateRandomly_y(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97622287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['subjective:, 23-year-old white female presents complaint allergies. used allergies lived seattle thinks worse here. past, tried claritin, zyrtec. worked short time seemed lose effectiveness. used allegra also. used last summer began using two weeks ago. appear working well. used over-the-counter sprays prescription nasal sprays. asthma doest require daily medication think flaring up.,medications: , medication currently ortho tri-cyclen allegra.,allergies: , known medicine allergies.,objective:,vitals: weight 130 pounds blood pressure 124/78.,heent: throat mildly erythematous without exudate. nasal mucosa erythematous swollen. clear drainage seen. tms clear.,neck: supple without adenopathy.,lungs: clear.,assessment:, allergic rhinitis.,plan:,1. try zyrtec instead allegra again. another option use loratadine. think prescription coverage might cheaper.,2. samples nasonex two sprays nostril given three weeks. prescription written well.',\n",
       "  '23-year-old white female presents complaint allergies.'],\n",
       " ['past medical history:, difficulty climbing stairs, difficulty airline seats, tying shoes, used public seating, lifting objects floor. exercises three times week home cardio. difficulty walking two blocks five flights stairs. difficulty snoring. muscle joint pains including knee pain, back pain, foot ankle pain, swelling. gastroesophageal reflux disease.,past surgical history:, includes reconstructive surgery right hand 13 years ago. ,social history:, currently single. ten drinks year. smoked significantly several months ago. smokes less three cigarettes day.,family history:, heart disease grandfathers, grandmother stroke, grandmother diabetes. denies obesity hypertension family members.,current medications:, none.,allergies:, allergic penicillin.,miscellaneous/eating history:, going support groups seven months lynn holmberg greenwich eastchester, new york feels appropriate program. poor experience greenwich program. eating history, emotional eater. like sweets. likes big portions carbohydrates. likes chicken steak. currently weighs 312 pounds. ideal body weight would 170 pounds. 142 pounds overweight. ,he lost 60 excess body weight would 84 pounds weigh 228.,review systems: ,negative head, neck, heart, lungs, gi, gu, orthopedic, skin. specifically denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, high cholesterol, pulmonary embolism, high blood pressure, cva, venous insufficiency, thrombophlebitis, asthma, shortness breath, copd, emphysema, sleep apnea, diabetes, leg foot swelling, osteoarthritis, rheumatoid arthritis, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, hemorrhoids, rectal bleeding, polyps, incontinence stool, urinary stress incontinence, cancer. denies cellulitis, pseudotumor cerebri, meningitis, encephalitis.,physical examination:, alert oriented x 3. cranial nerves ii-xii intact. afebrile. vital signs stable.',\n",
       "  'consult laparoscopic gastric bypass.'],\n",
       " ['history present illness: , seen abc today. pleasant gentleman 42 years old, 344 pounds. 59\". bmi 51. overweight ten years since age 33, highest 358 pounds, lowest 260. pursuing surgical attempts weight loss feel good, get healthy, begin exercise again. wants able exercise play volleyball. physically, sluggish. gets tired quickly. go often. loses weight always regains gains back lost. biggest weight loss 25 pounds three months gained back. six months drinking alcohol taking many calories. multiple commercial weight loss programs including slim fast one month one year ago atkins diet one month two years ago.,past medical history: , difficulty climbing stairs, difficulty airline seats, tying shoes, used public seating, difficulty walking, high cholesterol, high blood pressure. asthma difficulty walking two blocks going eight ten steps. sleep apnea snoring. diabetic, medication. joint pain, knee pain, back pain, foot ankle pain, leg foot swelling. hemorrhoids.,past surgical history: , includes orthopedic knee surgery.,social history: , currently single. drinks alcohol ten twelve drinks week, drink five days week binge drink. smokes one half pack day 15 years, recently stopped smoking past two weeks.,family history: , obesity, heart disease, diabetes. family history negative hypertension stroke.,current medications:, include diovan, crestor, tricor.,miscellaneous/eating history: ,he says couple friends heart attacks died. used drink everyday, stopped two years ago. drinks weekends. second week chantix, medication come smoking completely. eating, eats bad food. single. eats things like bacon, eggs, cheese, cheeseburgers, fast food, eats four times day, seven morning, noon, 9 p.m., 2 a.m. currently weighs 344 pounds 59\". ideal body weight 160 pounds. 184 pounds overweight. lost 70 excess body weight would 129 pounds would get 215.,review systems: , negative head, neck, heart, lungs, gi, gu, orthopedic, skin. also positive gout. denies chest pain, heart attack, coronary artery disease, congestive heart failure, arrhythmia, atrial fibrillation, pacemaker, pulmonary embolism, cva. denies venous insufficiency thrombophlebitis. denies shortness breath, copd, emphysema. denies thyroid problems, hip pain, osteoarthritis, rheumatoid arthritis, gerd, hiatal hernia, peptic ulcer disease, gallstones, infected gallbladder, pancreatitis, fatty liver, hepatitis, rectal bleeding, polyps, incontinence stool, urinary stress incontinence, cancer. denies cellulitis, pseudotumor cerebri, meningitis, encephalitis.,physical examination: ,he alert oriented x 3. cranial nerves ii-xii intact. neck soft supple. lungs: positive wheezing bilaterally. heart regular rhythm rate. abdomen soft. extremities: 1+ pitting edema.,impression/plan:, explained risks potential complications laparoscopic gastric bypass detail include bleeding, infection, deep venous thrombosis, pulmonary embolism, leakage gastrojejuno-anastomosis, jejunojejuno-anastomosis, possible bowel obstruction among potential complications. understands. wants proceed workup evaluation laparoscopic roux-en-y gastric bypass. need get letter approval dr. xyz. need see nutritionist mental health worker. need upper endoscopy either dr. xyz. need go dr. xyz previously sleep study. need another sleep study. need h. pylori testing, thyroid function tests, lfts, glycosylated hemoglobin, fasting blood sugar. performed, submit insurance approval.',\n",
       "  'consult laparoscopic gastric bypass.'],\n",
       " ['2-d m-mode: , ,1. left atrial enlargement left atrial diameter 4.7 cm.,2. normal size right left ventricle.,3. normal lv systolic function left ventricular ejection fraction 51.,4. normal lv diastolic function.,5. pericardial effusion.,6. normal morphology aortic valve, mitral valve, tricuspid valve, pulmonary valve.,7. pa systolic pressure 36 mmhg.,doppler: , ,1. mild mitral tricuspid regurgitation.,2. trace aortic pulmonary regurgitation.',\n",
       "  '2-d m-mode. doppler.'],\n",
       " ['1. left ventricular cavity size wall thickness appear normal. wall motion left ventricular systolic function appears hyperdynamic estimated ejection fraction 70 75. near-cavity obliteration seen. also appears increased left ventricular outflow tract gradient mid cavity level consistent hyperdynamic left ventricular systolic function. abnormal left ventricular relaxation pattern seen well elevated left atrial pressures seen doppler examination.,2. left atrium appears mildly dilated.,3. right atrium right ventricle appear normal.,4. aortic root appears normal.,5. aortic valve appears calcified mild aortic valve stenosis, calculated aortic valve area 1.3 cm square maximum instantaneous gradient 34 mean gradient 19 mm.,6. mitral annular calcification extending leaflets supportive structures thickening mitral valve leaflets mild mitral regurgitation.,7. tricuspid valve appears normal trace tricuspid regurgitation moderate pulmonary artery hypertension. estimated pulmonary artery systolic pressure 49 mmhg. estimated right atrial pressure 10 mmhg.,8. pulmonary valve appears normal trace pulmonary insufficiency.,9. pericardial effusion intracardiac mass seen.,10. color doppler suggestive patent foramen ovale lipomatous hypertrophy interatrial septum.,11. study somewhat technically limited hence subtle abnormalities could missed study.,',\n",
       "  '2-d echocardiogram']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c491053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import csv\n",
    "\n",
    "metric = load_metric(\"rouge\")\n",
    "data1 = pd.read_csv('./mt_samples_preproc.csv',encoding='iso-8859-1') \n",
    "\n",
    "transcriptions_unseen = []\n",
    "transcriptions_seen = []\n",
    "actual_summaries_unseen = []\n",
    "actual_summaries_seen = []\n",
    "predicted_summaries_unseen = []\n",
    "predicted_summaries_seen = []\n",
    "\n",
    "transcriptions_unseen.append('transcription')\n",
    "transcriptions_seen.append('transcription')\n",
    "actual_summaries_unseen.append('actual_summaries')\n",
    "actual_summaries_seen.append('actual_summaries')\n",
    "predicted_summaries_unseen.append('predicted_summaries')\n",
    "predicted_summaries_seen.append('predicted_summaries')\n",
    "\n",
    "\n",
    "for pair in pairs_v:\n",
    "\n",
    "    output_words, attentions = evaluate(encoder1, attn_decoder1, pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    transcriptions_unseen.append(pair[0])\n",
    "    predicted_summaries_unseen.append(output_sentence)\n",
    "    actual_summaries_unseen.append(pair[1])\n",
    "\n",
    "for pair in pairs:\n",
    "\n",
    "    output_words, attentions = evaluate(encoder1, attn_decoder1, pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    transcriptions_seen.append(pair[0])\n",
    "    predicted_summaries_seen.append(output_sentence)\n",
    "    actual_summaries_seen.append(pair[1])\n",
    "\n",
    "rows_unseen = zip(transcriptions_unseen, actual_summaries_unseen, predicted_summaries_unseen)\n",
    "rows_seen = zip(transcriptions_seen, actual_summaries_seen, predicted_summaries_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cefaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mtsamples_output_seen.csv', \"w\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows_seen:\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open('mtsamples_output_unseen.csv', \"w\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows_unseen:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8458b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.6664090847883721, recall=0.6982480315486486, fmeasure=0.6625535051826185), mid=Score(precision=0.6734664499049955, recall=0.7067742628310387, fmeasure=0.6699195525617391), high=Score(precision=0.680897087915148, recall=0.7155699617583892, fmeasure=0.6780071549588066)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.5686601254801196, recall=0.6125457714105063, fmeasure=0.5722119367028938), mid=Score(precision=0.5773309542940064, recall=0.6226878163979281, fmeasure=0.5811595889376151), high=Score(precision=0.585384363502145, recall=0.6325548531473143, fmeasure=0.5899670323008036)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.6551274218137426, recall=0.6878311367132569, fmeasure=0.6521948720363728), mid=Score(precision=0.6623554197418038, recall=0.6969978067420624, fmeasure=0.6602393689762978), high=Score(precision=0.6699321471934618, recall=0.7051005104489076, fmeasure=0.6674858661223655)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.6550141295038399, recall=0.6870639174047195, fmeasure=0.6513294170023243), mid=Score(precision=0.6620593611720412, recall=0.6967166571144376, fmeasure=0.6598756590441122), high=Score(precision=0.6696573617252826, recall=0.705139771788098, fmeasure=0.6674028420177226))}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predicted_summaries_seen, references=actual_summaries_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1597f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.4096261106790558, recall=0.4089115837866178, fmeasure=0.38568663368088096), mid=Score(precision=0.434247261667181, recall=0.4368128004601798, fmeasure=0.4106441778098331), high=Score(precision=0.45847381281104793, recall=0.4648930409763885, fmeasure=0.4351587968060159)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.28256497048929574, recall=0.2979496951410391, fmeasure=0.2726358566927594), mid=Score(precision=0.3106235062847339, recall=0.32585437552790775, fmeasure=0.2990527548397035), high=Score(precision=0.33411792985469124, recall=0.3541113590103674, fmeasure=0.32347935456463395)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.39407362954356, recall=0.39507470249746596, fmeasure=0.37108075732826806), mid=Score(precision=0.4201589550411787, recall=0.4237843973307931, fmeasure=0.3975179569043381), high=Score(precision=0.4448608022395026, recall=0.45138295328778544, fmeasure=0.4220999856452086)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.394560362200412, recall=0.3949250112378624, fmeasure=0.37201388550975284), mid=Score(precision=0.41932688810376434, recall=0.4232722279322685, fmeasure=0.39733529520708205), high=Score(precision=0.4469980853867035, recall=0.45074621590134284, fmeasure=0.4224734783449153))}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predicted_summaries_unseen, references=actual_summaries_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19c1c813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actual_summaries',\n",
       " 'chronic adenotonsillitis adenotonsillar hypertrophy. upper respiratory tract infection mild acute laryngitis.',\n",
       " '37-year-old admitted emergency, presented symptoms chest pain, described pressure-type dull ache discomfort precordial region. also, shortness breath noted without diaphoresis. symptoms last 3 4 days especially stress. relation exertional activity. aggravating relieving factors.',\n",
       " 'patient 63-year-old white male admitted hospital chf lymphedema.',\n",
       " 'patient multiple problems, main one chest pain night.',\n",
       " 'patient suffering intractable back leg pain.',\n",
       " 'patient presents complaint lump upper outer quadrant right breast',\n",
       " 'patient history right upper pons right cerebral peduncle infarction.',\n",
       " 'patient 57-year-old female invasive ductal carcinoma left breast, t1c, nx, m0 left breast carcinoma.',\n",
       " 'patient history mesothelioma likely mild dementia, likely alzheimer type.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_summaries_unseen[:10]\n",
    "#transcripts, act, pred = zip(*mapped)\n",
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95c2c7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicted_summaries',\n",
       " 'chronic recurrent upper biopsies. <EOS>',\n",
       " 'admitted admitted chest male admitted chief ct chest presented symptoms last several days. patients progressive symptoms last night. also noted could noted looked extremely pale. <EOS>',\n",
       " 'patient 63-year-old male history left chf <EOS>',\n",
       " 'patient multiple problems, one chest pain night. one week prior admission. <EOS>',\n",
       " 'patient suffering intractable leg pain. <EOS>',\n",
       " 'patient presents right arm breast history <EOS>',\n",
       " 'patient right upper history right infarction. patient states received fresh increased physical right upper extremity pain, patients parents <EOS>',\n",
       " 'patient 57-year-old female invasive <EOS>',\n",
       " 'patient history mesothelioma history dementia, <EOS>']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_summaries_unseen[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bbd37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
